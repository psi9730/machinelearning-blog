<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Favicon Icon -->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.png">

    <title>Character-Level Language Modeling with Deeper Self-Attention</title>
    <meta name="description"
          content="Paper review on “Character-Level Language Modeling with Deeper Self-Attention(2018-08-09)”">

    <link rel="canonical" href="http://psi9730.github.io/machinelearning-blog/nlp/2019/10/23/Character-Level-Language-Modeling-With-Deeper-Self-Attention.html">
    <link rel="alternate" type="application/rss+xml" title="Seungil's development Blog" href="http://psi9730.github.io/machinelearning-blog/feed.xml">

    <script type="text/javascript" src="/bower_components/jquery/jquery.min.js"></script>

    <!-- Third-Party CSS -->
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/bower_components/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/bower_components/hover/css/hover-min.css">
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/bower_components/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/assets/css/syntax.css">

    <!-- My CSS -->
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/assets/css/common.css">

    <!-- CSS set in page -->
    

    <!-- CSS set in layout -->
    
    <link rel="stylesheet" href="http://psi9730.github.io/machinelearning-blog/assets/css/sidebar-post-nav.css">
    

    <script type="text/javascript" src="http://psi9730.github.io/machinelearning-blog/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>

</head>


    <body>

    <header class="site-header">
    <div class="container">
        <a id="site-header-brand" href="/" title="Park Seungil">
            <span class="octicon octicon-mark-github"></span> Park Seungil
        </a>
        <nav class="site-header-nav" role="navigation">
            
            <a href="/"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="Home">
                Home
            </a>
            
            <a href="/open-source"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="Open-Source">
                Open-Source
            </a>
            
            <a href="/blog"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="Blog">
                Blog
            </a>
            
            <a href="/bookmark"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="Bookmark">
                Bookmark
            </a>
            
            <a href="/about"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="About">
                About
            </a>
            
        </nav>
    </div>
</header>


        <div class="content">
            <section class="jumbotron geopattern" data-pattern-id="Character-Level Language Modeling with Deeper Self-Attention">
    <div class="container">
        <div id="jumbotron-meta-info">
            <h1>Character-Level Language Modeling with Deeper Self-Attention</h1>
            <span class="meta-info">
                
                
                <span class="octicon octicon-calendar"></span> 2019/10/23
                
            </span>
        </div>
    </div>
</section>
<script>
    $(document).ready(function(){

        $('.geopattern').each(function(){
            $(this).geopattern($(this).data('pattern-id'));
        });

    });
</script>
<article class="post container" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="row">

        
        <div class="col-md-8 markdown-body">

            <p>Paper review on “Character-Level Language Modeling with Deeper Self-Attention(2018-08-09)”</p>

<h2 id="introduction">Introduction</h2>
<p>LSTM, RNN 의 성능은 long-term context를 기억하고 있다는데에 있다. 이번 논문에서는 fixed context deep(64-layer) transformer model에 character level language modeling을 적용해 문장예측에 높은 성능을 가짐을 보인다. deep layer을 이용하는만큼 speed convergence, additional regularizer기능을 제공해주는 auxiliary losses(Multiple Positions, Intermediate Layer Losses, Mulitple Targets)을 제안한다.</p>

<h2 id="character-transformer-model">Character Transformer model</h2>
<p><img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-1.png" alt="image-1" /><br />
language 모델은 다음과 같은 방식으로 예측 sequence probability을 예측하며, 64 transformer layers을 이용하며 각 포지션이 leftward하게 영향을 받기 위해 Figure 1 처럼 mask을 적용시킨다.<br />
<img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-5.png" alt="image-2" /></p>

<h2 id="auxiliary-losses">Auxiliary Losses</h2>
<p>네트워크가 10 layers이상 깊어지면 slow convergence 와 poor accuracy문제가 발생하게 된다. 이에 본 논문에서는 다음과 같은 auxiliary losses을 제안한다. 이는 speed up convergence와 additional regularizer 역할을 한다.<br />
각각의 auxiliary losses는 total loss of network에 더해지게 되며, 상대적으로 낮은 weight을 가지며. 각 losses마다 own schedule of decay 를 가진다.</p>

<h3 id="mulitple-positions">Mulitple Positions</h3>
<p><img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-2.png" alt="image-3" /><br />
예측을 마지막 레이어 마지막 값에서 마지막 레이어 모든 값으로 바꾼다. 이는 때때로 하나 또는 두개의 단어로 다음 단어를 예측해야하는 상황을 만들지만, 실험적으로 이 loss정책은 트레이닝 속도를 올리고 더 좋은 결과를 가지게 해준다.</p>

<h3 id="intermediate-layer-losses">Intermediate Layer Losses</h3>
<p><img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-3.png" alt="image-4" /><br />
final layer을 제외하고 lower layers에도 predictions을 구하고 loss을 만드는 것을 말한다. lower layers는 상대적으로 낮은 contribute을 가지게 되며, l^th intermediate layer는 l/2n of training이후에 loss에 영향을 주지 않게 된다.</p>

<h3 id="multiple-target">Multiple Target</h3>
<p><img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-4.png" alt="image-5" /><br />
예측시에 하나의 값이 아닌 multiple한 값을 예측한다. extra targets 의 weight는 0.5라는 값을 곱해서 loss을 만들게 구현한다.</p>

<h2 id="positional-embedding">Positional Embedding</h2>
<p>64 layers는 매우 깊음으로 sinusodial timing singal을 input에서만 더하는 것으로는, propagation하면서 그 기능이 미미해 질 수 있다 판단했다.이에 본 논문에서는 learned positional embedding을 각 transformer layer input sequence에 더하게 된다. 이 때 layer 마다 positional embedding은 공유하지 않는다.</p>

<h2 id="result">Result</h2>
<p><img src="/assets/images/character-level-language-modeling-with-deeper-self-attention-5.png" alt="image-6" /><br />
character and accuracy of model is best on layer 64 tranformers. 그리고 적용시킨 auxiliary losses에 대해 ablation experiments을 한 결과. 모든 auxiliary losses을 고려했을 때 최상의 결과를 가져 왔다. 또한 같은 모델을 word모델에 적용시 PPL이 word level model이 더낮게 나왔는데 이는 추가 연구가 필요할 것 같다.</p>

<p>또한 분석결과 character level model이 prefer actual English words over non-existent words함을 확인했고, transformer self-attention구조가 copy sequences over long distances능력을 가져다줌을 예상한다.</p>

<h2 id="bpc">bpc란?</h2>
<p>After all input has been read and encoded, the total length (in bits) of the result is measured and divided by the number of characters in the original, uncompressed input. If the model is good, it will have predicted the characters with high accuracy, so the bit sequence used for each character will have been short on average, hence the total bits per character will be low.</p>

<ul>
  <li>[what-is-bpc] (https://stackoverflow.com/questions/17797922/how-to-calculate-bits-per-character-of-a-string-bpc)</li>
</ul>

<h2 id="section">참고문헌</h2>
<ul>
  <li><a href="https://arxiv.org/abs/1803.02155">Character-Level Language Modeling with Deeper Self-Attention</a></li>
</ul>


            <!-- Comments -->
            
<div class="comments">
    <div id="disqus_thread"></div>
    <script>
        /**
         * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
         */
        /*
         var disqus_config = function () {
         this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
         this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
         };
         */
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');

            s.src = '//my_disque_settings/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


        </div>

        <div class="col-md-4">
            <h3>Post Directory</h3>
<div id="post-directory-module">
<section class="post-directory">
    <!-- Links that trigger the jumping -->
    <!-- Added by javascript below -->
    <dl></dl>
</section>
</div>

<script type="text/javascript">

    $(document).ready(function(){
        $( "article h2" ).each(function( index ) {
            $(".post-directory dl").append("<dt><a class=\"jumper\" hre=#" +
                    $(this).attr("id")
                    + ">"
                    + $(this).text()
                    + "</a></dt>");

            var children = $(this).nextUntil("h2", "h3")

            children.each(function( index ) {
                $(".post-directory dl").append("<dd><a class=\"jumper\" hre=#" +
                        $(this).attr("id")
                        + ">"
                        + "&nbsp;&nbsp;- " + $(this).text()
                        + "</a></dd>");
            });
        });

        var fixmeTop = $('#post-directory-module').offset().top - 100;       // get initial position of the element

        $(window).scroll(function() {                  // assign scroll event listener

            var currentScroll = $(window).scrollTop(); // get current position

            if (currentScroll >= fixmeTop) {           // apply position: fixed if you
                $('#post-directory-module').css({      // scroll to that element or below it
                    top: '100px',
                    position: 'fixed',
                    width: 'inherit'
                });
            } else {                                   // apply position: static
                $('#post-directory-module').css({      // if you scroll above it
                    position: 'inherit',
                    width: 'inherit'
                });
            }

        });

        $("a.jumper").on("click", function( e ) {

            e.preventDefault();

            $("body, html").animate({
                scrollTop: ($( $(this).attr('hre') ).offset().top - 100)
            }, 600);

        });
    });

</script>
        </div>
        

    </div>

</article>

        </div>

    <footer class="container">

    <div class="site-footer">

        <div class="copyright pull-left">
            <!-- Please keep this line to let others know where this theme comes from. Thank you :D -->
            Power by <a href="https://github.com/psi9730/development-blog">psi9730</a>
        </div>

        <a href="https://github.com/psi9730" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <div class="pull-right">
            <a href="javascript:window.scrollTo(0,0)" >TOP</a>
        </div>

    </div>

    <!-- Third-Party JS -->
    <script type="text/javascript" src="http://psi9730.github.io/machinelearning-blog/bower_components/geopattern/js/geopattern.min.js"></script>

    <!-- My JS -->
    <script type="text/javascript" src="http://psi9730.github.io/machinelearning-blog/assets/js/script.js"></script>

    

    

</footer>


    </body>

</html>
